{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core concepts\n",
    "\n",
    "\n",
    "## Ploomber's core: Tasks, Products, DAG and Clients\n",
    "\n",
    "To get started with ploomber you only have to learn four concepts:\n",
    "\n",
    "1. Task. A unit of work that takes some input and produces a persistent change\n",
    "2. Product. A persistent change *produced* by a Task (e.g. a file in the local filesystem, a table in a remote database)\n",
    "3. DAG. A collection of Tasks used to specify dependencies among them (use output from Task A as input for Task B)\n",
    "4. Client. An object that keeps communication with an external system (e.g. a database)\n",
    "\n",
    "There is a standard [Task API](../api.rst#ploomber.tasks.Task) defined by an abstract class, this is also true for [Products](../api.rst#ploomber.products.Product) and [Clients](../api.rst#ploomber.clients.Client). Which means you only have to learn the concept once and all concrete classes will behave in the same way.\n",
    "\n",
    "\n",
    "## The DAG lifecycle: Declare, render, build\n",
    "\n",
    "A DAG goes through three steps before being executed:\n",
    "\n",
    "1. Declaration. A DAG is created and Tasks are added to it\n",
    "2. Rendering. Placeholders are resolved and validation is performed on Task inputs\n",
    "3. Building. All *outdated* Tasks are executed in the appropriate order (run upstream task dependencies first)\n",
    "\n",
    "### Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from ploomber import DAG\n",
    "from ploomber.tasks import PythonCallable, SQLUpload, SQLScript\n",
    "from ploomber.clients import SQLAlchemyClient\n",
    "from ploomber.products import File, SQLiteRelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest Task is PythonCallable, which takes a callable (e.g. a function) as its first argument. The only requirement for the functions is to have a product\n",
    "argument, if the task has dependencies, it must have an upstream argument as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_task(product):\n",
    "    pd.DataFrame({'one_column': [1, 2, 3]}).to_csv(str(product))\n",
    "\n",
    "def _another_task(upstream, product):\n",
    "    df = pd.read_csv(str(upstream['one']))\n",
    "    df['another_column'] = df['one_column'] + 1\n",
    "    df.to_csv(str(product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonCallable: another -> File('another_file.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag = DAG()\n",
    "\n",
    "# instantiate two tasks and add them to the DAG\n",
    "one_task = PythonCallable(_one_task, File('one_file.csv'), dag, name='one')\n",
    "another_task = PythonCallable(_another_task, File('another_file.csv'), dag, name='another')\n",
    "# declare dependencies: another_task depends on one_task\n",
    "one_task >> another_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the previous function definitions we use `str(product)`, since products are custom objects, they will not work directly when used as parameters to external functions, hence using `str` will return a string representation that can be used. For `File` the path to the file will be returned, other products implement different logic, for example a `SQLRelation` returns a `\"schema\".\"name\"` string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering\n",
    "\n",
    "To generate a Product, Tasks use a combination of inputs and a `source`. The kind of source depends on the kind of Task, `PythonCallable` uses a Python function as source, `SQLScript` uses a string with SQL code as source, `SQLUpload` uses a string to a file as source. Rendering is the process where any necessary preparation and validation to the source takes place.\n",
    "\n",
    "One use case for this is to avoid redudant code. If a Task is declared to have an upstream dependency, it means that it will take the upstream Product as input, instead of declaring the Product twice, we can refer to it in the downstream task using a placeholder. Let's see an example using `SQLUpload`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SQLUpload: my_table -> SQLiteRelation('None.my_table')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = SQLAlchemyClient('sqlite:///my_db.db')\n",
    "\n",
    "# Tasks that use clients have a client argument, but you can also define\n",
    "# DAG-level clients\n",
    "dag.clients[SQLUpload] = client\n",
    "dag.clients[SQLiteRelation] = client\n",
    "dag.clients[SQLScript] = client\n",
    "\n",
    "# Take the product from the upstream task named \"another\" and use it as source\n",
    "my_table = SQLUpload(source='{{upstream[\"another\"]}}',\n",
    "                     product=SQLiteRelation((None, 'my_table', 'table')),\n",
    "                     dag=dag,\n",
    "                     name='my_table')\n",
    "\n",
    "another_task >> my_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb4b94e0b5e49a08efeda439ece42d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'another_file.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.render()\n",
    "\n",
    "# let's see the rendered value:\n",
    "str(my_table.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important use case for placeholders are parametrized SQL queries. `SQLScript` runs SQL code in a database that creates a table or a view. Since ploomber requires sources (SQL code) and products (a table/view) to be declared separately we use placeholdes to only declare the product once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SQLScript: second_table -> SQLiteRelation('None.second_table')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = \"\"\"\n",
    "DROP TABLE IF EXISTS {{product}};\n",
    "\n",
    "CREATE TABLE {{product}}\n",
    "AS SELECT * FROM {{upstream[\"my_table\"]}}\n",
    "WHERE one_column = 1\n",
    "\"\"\"\n",
    "\n",
    "# instead of declaring \"second_table\" twice, we declare it in product and refer to it in source\n",
    "second_table = SQLScript(source=source,\n",
    "                     product=SQLiteRelation((None, 'second_table', 'table')),\n",
    "                     dag=dag,\n",
    "                     name='second_table')\n",
    "\n",
    "my_table >> second_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b08489e404437d836fc3dfe3b3f8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DAG(\"No name\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DROP TABLE IF EXISTS second_table;\n",
      "\n",
      "CREATE TABLE second_table\n",
      "AS SELECT * FROM my_table\n",
      "WHERE one_column = 1\n"
     ]
    }
   ],
   "source": [
    "print(str(dag['second_table'].source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ploomber uses [jinja2](https://jinja.palletsprojects.com/en/2.11.x/api/) for rendering, which opens a wide range of possibilities rendering SQL source code. Note that this time, we didn't use the `str` operator explicitely as we did for PythonCallable, this is because jinja automatically casts objects to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rendering is a pre-processing step where placeholders are resolved and\n",
    "# a few validation checks are run. Placeholders exist to succinctly declare\n",
    "# DAGs, once a parameter is declared, it can be used in several contexts. Placeholders are extremely useful for propagating values in a DAG.\n",
    "\n",
    "# Once you declare a dependency, you make the product(s) of the upstream Task\n",
    "# available to the downstream Task at render time, this allows you to only\n",
    "# define a product once and propagate it to downstream tasks.\n",
    "\n",
    "# Within the downstream task, you can access upstream dependencies using jinja syntax via the `upstream` key. Any parameter passed to the Task via the\n",
    "# `param` parameter, will also be available at rendering time.\n",
    "\n",
    "# A task Product does not have to be fully defined at declaration time. Rendering is the process where a DAG object resolves any dependencies\n",
    "\n",
    "\n",
    "# dag = DAG()\n",
    "\n",
    "# one_task = PythonCallable(_one_task, File('one_file'), dag, 'one')\n",
    "# another_task = PythonCallable(_another_task, File('{{upstream[\"one\"]}}_and_another_file'), dag, 'another')\n",
    "# one_task >> another_task\n",
    "\n",
    "# dag.render()\n",
    "\n",
    "# another_task.product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "If anything in the rendering process goes wrong, you will see a detailed traceback to debug. Furthermore\n",
    "\n",
    "\n",
    "\n",
    "talk about debugging rendering, using the traceback (errors are details) \n",
    "but also doing task.params (explain pre and post render difference)\n",
    "talk about source code tracking, parameter passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build\n",
    "\n",
    "Once rendering is done, we can build our DAG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fe1373f8224cc8b9030b6df94d3102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516a3802af474ca6a155b4e68f25bc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name        </th><th>Ran?  </th><th style=\"text-align: right;\">  Elapsed (s)</th><th style=\"text-align: right;\">  Percentage</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>one         </td><td>False </td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td>another     </td><td>False </td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td>my_table    </td><td>False </td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td>second_table</td><td>False </td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "name          Ran?      Elapsed (s)    Percentage\n",
       "------------  ------  -------------  ------------\n",
       "one           False               0             0\n",
       "another       False               0             0\n",
       "my_table      False               0             0\n",
       "second_table  False               0             0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time we run our pipeline, all Tasks are executed, but the real power of ploomber is running builds over and over again. Ploomber keeps track of each Task's status and only executed outdated ones, since we just built our pipeline, nothing will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dc7c0c05d942a88e04399e1a7b4a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0986965d1c1e4aac9cc0d62e60d0e8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name        </th><th>Ran?  </th><th style=\"text-align: right;\">  Elapsed (s)</th><th style=\"text-align: right;\">  Percentage</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>one         </td><td>False </td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td>another     </td><td>False </td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td>my_table    </td><td>False </td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "<tr><td>second_table</td><td>False </td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">           0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "name          Ran?      Elapsed (s)    Percentage\n",
       "------------  ------  -------------  ------------\n",
       "one           False               0             0\n",
       "another       False               0             0\n",
       "my_table      False               0             0\n",
       "second_table  False               0             0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task status\n",
    "\n",
    "Upon sucessful execution, a Task will save metadata along with the Product, to keep track of status in subsequent builds. Upon DAG execution (even if some tasks fail), another call to `dag.build()` will only trigger execution on outdated tasks. A task is run if any of the following conditions is true:\n",
    "\n",
    "1. No product (when a Task is run for the first time)\n",
    "2. No metadata (when a Task crashes, no metadata is saved)\n",
    "3. Any upstream source changed (e.g. an upstream SQL script changed)\n",
    "4. Source changed (the the Task source changed)\n",
    "\n",
    "These rules enable the following use cases:\n",
    "\n",
    "1. Fast incremental builds (Modify any Task source, next build will only run affected Tasks)\n",
    "2. Crash recovery (If a DAG crashes, the next run will start where it was interrupted)\n",
    "\n",
    "\n",
    "### Task parameters\n",
    "\n",
    "There is one last remaining Task argument: `params`, they are optional parameters whose effect varies depending on the kind of Task. `PythonCallable` just passes them when calling the underlying function, Tasks that take SQL code as source, pass them directly to the source (they are available as placeholders), `NotebookRunner` (which runs Jupyter notebooks), passes them as parameters using [papermill](https://github.com/nteract/papermill).\n",
    "\n",
    "As a general advice, it is best to keep `params` short, their main use case for creating dynamic DAGs (whose number of Tasks is determined using control structures). Dynamic DAGs are covered in a more advanced tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
