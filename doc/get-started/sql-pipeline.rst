SQL pipelines
=============

Connecting to databases
-----------------------

The first step to write a SQL pipeline is to tell Ploomber how to connect to
the database, this is done by providing a function that returns either a
:py:mod:`ploomber.clients.SQLAlchemyClient` or a
:py:mod:`ploomber.clients.DBAPIClient`. The former are a bit simpler to
configure, we'll cover such case for this example.

``SQLAlchemyClient`` takes a single argument, the database URI. As the name
suggests, it uses SQLAlchemy under the hood, so any database supported by such
library is supported as well.

`Click here for documentation on database URIs <https://docs.sqlalchemy.org/en/13/core/engines.html>`_.


Product's metadata
------------------


Configuring ``pipeline.yaml``
-----------------------------

.. code-block:: yaml
    :class: text-editor
    :name: pipeline-yaml

    clients:
        SQLRelation: config.load_client

    tasks:
        # tasks...


Parametrized SQL scripts
------------------------

Similar to what we saw in the previous tutorial, each script contains an
``upstream`` and a ``product`` parameter that helps structure the pipeline. To
get this to work for SQL scripts we use the `jinja templating library <https://jinja.palletsprojects.com/en/2.11.x/>`_.

Let's see an example:

.. code-block:: postgresql
    :class: text-editor
    :name: task-sql

    {% set product = SQLRelation(['schema', 'name', 'table']) %}

    -- {{product}} gets replaced by the variable defined above
    DROP TABLE IF EXISTS {{product}};

    CREATE TABLE {{product}} AS
    -- this task depends on the output generated by a task named "clean"
    SELECT * FROM {{upstream['clean']}}
    WHERE x > 10

(add command to print rendered code)


Mixing Python and SQL scripts via ``SQLDump``
---------------------------------------------

Wrapping up
-----------