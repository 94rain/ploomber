Ploomber
========

.. image:: https://travis-ci.org/ploomber/ploomber.svg?branch=master
    :target: https://travis-ci.org/ploomber/ploomber.svg?branch=master

.. image:: https://readthedocs.org/projects/ploomber/badge/?version=latest
    :target: https://ploomber.readthedocs.io/en/latest/?badge=latest
    :alt: Documentation Status

.. image:: https://mybinder.org/badge_logo.svg
 :target: https://mybinder.org/v2/gh/ploomber/projects/master


Write your pipeline tasks as Python and SQL scripts in a ``pipeline.yaml`` file, Ploomber will figure out execution order by extracting dependencies from them.

.. code-block:: python

    # annotated python file, it will be converted to a notebook during execution
    import pandas as pd

    # + tags=["parameters"]
    # this script depends on the output generated by a task named "clean"
    upstream = {'clean': None}
    product = None

    # during execution, a new cell is added here

    # +
    df = pd.read_csv(upstream['some_task'])
    # do data processing...
    df.to_csv(product['data'])

.. code-block:: sqlite

    CREATE TABLE {{product}}
    -- this task depends on the output generated by a task named "clean"
    SELECT * FROM {{upstream['clean']}}
    WHERE x > 10

Ploomber also keeps track of source code changes to speed up builds by skipping up-to-date tasks. This is a great way of interactively develop your projects, sync work with your team and quickly recover from crashes (just fix the bug and build again).


`Try out the live demo (no installation required) <https://mybinder.org/v2/gh/ploomber/projects/master?filepath=spec%2FREADME.md>`_.

`Click here for documentation <https://ploomber.readthedocs.io/>`_.


Works with Python 3.5 and higher.


Example
-------

.. code-block:: yaml

    # pipeline.yaml
    
    # clean data from the raw table
    - source: clean.sql
      product: clean_data
      # function that returns a db client
      client: config.get_client
    
    # aggregate clean data
    - source: aggregate.sql
      product: agg_data
      client: config.get_client
    
    # dump data to a csv file
    - class: SQLDump
      source: dump_agg_data.sql
      product: output/data.csv  
    
    # visualize data from csv file
    - source: plot.py
      product:
        # where to save the executed notebook
        nb: output/executed-notebook-plot.ipynb
        # tasks can generate other outputs
        data: output/some_data.csv


To run your pipeline:

.. code-block:: bash

    python -m ploomber.entry pipeline.yaml --action build


If you build again, tasks whose source code is the same (and all
upstream dependencies) are skipped.


Start an interactive session (note the double dash):

.. code-block:: bash

    ipython -i -m ploomber.entry pipeline.yaml -- --action status


During an interactive session:


.. code-block:: python

    # visualize dependencies
    dag.plot()

    # develop your Python script interactively
    dag['task'].develop()

    # line by line debugging
    dag['task'].debug()


Install
-------

.. code-block:: shell

    pip install ploomber


To install Ploomber along with all optional dependencies:

.. code-block:: shell

    pip install "ploomber[all]"

``graphviz`` is required for plotting pipelines:

.. code-block:: shell

    # if you are using conda (recommended)
    conda install graphviz
    # if you are using homebrew
    brew install graphviz
    # for other systems, see: https://www.graphviz.org/download/



Python API
----------

There is also a Python API for advanced use cases. This API allows you build
flexible abstractions such as dynamic pipelines, where the exact number of
tasks is determined by its parameters.
